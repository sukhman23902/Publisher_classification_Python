# -*- coding: utf-8 -*-
"""Site_status_verification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n6FBjorXwmx_AGG3T_bki57qLPpsLbYo
"""

import requests
import pandas as pd
import socket
import time
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

def is_domain_resolvable(domain):
    try:
        socket.create_connection((domain, 80), timeout=5)
        return True
    except (socket.gaierror, socket.timeout, ConnectionRefusedError):
        return False

def check_site_status(domain):
    site_status = "Not Working"
    http_status = "N/A"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
        "Accept-Language": "en-US,en;q=0.9",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8"
    }

    if not is_domain_resolvable(domain):
        return domain, "N/A", "Not Working"

    try:
        response = requests.get(f"https://{domain}", headers=headers, timeout=5)
        http_status = response.status_code
        if 200 <= response.status_code < 400:
            site_status = "Working"
    except requests.RequestException as e:
        logging.error(f"HTTP request failed for {domain}: {e}")
        site_status = "Not Working"

    return domain, http_status, site_status

def process_domains(domain_list):
    results = []
    with ThreadPoolExecutor(max_workers=20) as executor:  # Increase workers for better performance
        future_to_domain = {executor.submit(check_site_status, domain): domain for domain in domain_list}
        for future in as_completed(future_to_domain):
            try:
                results.append(future.result())
            except Exception as e:
                domain = future_to_domain[future]
                logging.error(f"Error processing {domain}: {e}")
                results.append((domain, "N/A", "Error"))

    # Save results to a CSV file
    df = pd.DataFrame(results, columns=["Domain", "HTTP Status", "Site Status"])
    df.to_csv("domain_status_results.csv", index=False)
    logging.info("Results saved to domain_status_results.csv")

if __name__ == "__main__":
    # Example list of domains (you can modify this to read from a file or input)
    domains = ["gauchazh.clicrbs.com.br"]
    process_domains(domains)